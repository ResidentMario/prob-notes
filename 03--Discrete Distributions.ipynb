{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The **discrete probability mass function** (pmf) is defined as $P(X=x) = P(\\cup\\{s \\in S: X(s) = x\\})$.\n",
    "* The **cumulative distribution function** (cdf) is defined as $P(X \\leq x) = \\sum_{y: y \\leq x}P(y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The **binomial theorem** states that $(x+y)^n=\\sum_{k=0}^n \\binom{n}{k} x^{n-k}y^k$. Proof is via induction: https://www.math.hmc.edu/calculus/tutorials/binomial_thm/induction.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The **binomial distribution** is the probability distribution for the selection of some number of successes ($x$) from some number of trials ($n$), with each trial independently having some chance of success ($p$).\n",
    "* Binomial PDF, by definition: $P[X\\sim binom[n,p](\\cdot)=x] = \\binom{n}{k}(p)^k (1-p)^{n-k}$.\n",
    "* Binomial CDF, by definition: $P[X\\sim binom[n,p](\\cdot)\\leq x] = \\sum_{i=0}^x \\binom{n}{k}(p)^i (1-p)^{n-i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If $X \\sim binom[n,p](x)$ then $E[X] = np$. Proof:\n",
    "\n",
    "$$E[binom[n,p](x)] = \\sum x_k P(x_k)$$\n",
    "$$= \\sum_{k=1}^n (k)\\binom{n}{k}(p)^k (1-p)^{n-k}$$\n",
    "$$= \\sum_{k=1}^n (k)\\binom{n}{k}(p)^k(1-p)^{n-k} \\quad \\because \\binom{n}{0}(p)^0(1-p)^{n-0}(0) = 0$$\n",
    "$$\\text{ }$$\n",
    "$$\\text{Lemma: $(k)\\binom{n}{k} = (k)\\dfrac{n!}{k!(n-k)!} = \\dfrac{n!}{(k-1)!(n-k)!}$} = (n)\\dfrac{n-1}{(k-1)(n-k)!} = (n)\\binom{n-1}{k-1}$$\n",
    "$$\\text{ }$$\n",
    "$$\\text{Substituting this into the equation we find that:}$$\n",
    "$$\\therefore E[binom[n,p](x)] = \\sum_{k=1}^n n \\binom{n-1}{k-1}(p)^k (1-p)^{n-k}$$\n",
    "$$= n\\sum_{k=1}^n \\binom{n-1}{k-1}(p)^k (1-p)^{n-k}$$\n",
    "$$= np\\sum_{k=1}^n \\binom{n-1}{k-1}(p)^{k-1} (1-p)^{n-k}$$\n",
    "$$= np\\sum_{k=0}^n-1 \\binom{n}{k}(p)^{k} (1-p)^{n-k}$$\n",
    "$$= np(p+1-p) \\quad \\because \\text{ binomial theorem}$$\n",
    "$$= np$$\n",
    "$$\\text{QED.}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If $X~binom[n,p](x)$ then $\\sigma_x^2 = npq$. Proof:\n",
    "\n",
    "$$\\text{Lemma: $E[X^2] = \\sum_{k=0}^n k^2 \\binom{n}{k} p^k q^{n-k}$}$$\n",
    "$$\\text{ }$$\n",
    "$$E[X^2] = \\sum_{k=0}^n k^2 \\binom{n}{k} p^k q^{n-k}$$\n",
    "$$= \\sum_{k=0}^n kn \\binom{n-1}{k-1}p^k q^{n-k} \\quad \\because k\\binom{n}{k} = n \\binom{n-1}{k-1}$$\n",
    "$$\\text{^ \"Binomial Factoring\" trick!}$$\n",
    "$$= np\\sum_{k=0}^n k \\binom{n-1}{k-1}p^{k-1}q^{n-k}$$\n",
    "$$= np\\sum_{k=1}^n k \\binom{n-1}{k-1}p^{k-1}q^{n-k} \\quad \\because \\text{term is 0 when $k=0$}$$\n",
    "$$\\text{Let $m=n-1$ and $j=k-1$. Then:}$$\n",
    "$$= np\\sum_{j=0}^m (j+1)\\binom{m}{j} p^j q^{m-j}$$\n",
    "$$= np\\sum_{j=0}^m j\\binom{m}{j} p^j q^{m-j} + np\\sum_{j=0}^m \\binom{m}{j} p^j q^{m-j}$$\n",
    "$$= np\\sum_{j=0}^m j\\binom{m}{j} p^j q^{m-j} + np(p+q) \\quad \\because \\text{Binomial Theorem}$$\n",
    "$$= np\\sum_{j=0}^m j\\binom{m}{j} p^j q^{m-j} + np$$\n",
    "$$= np\\sum_{j=0}^m m\\binom{m-1}{j-1} p^j q^{m-j} + np \\quad \\because k\\binom{n}{k} = n \\binom{n-1}{k-1}\\text{ (again)}$$\n",
    "$$= nmp^2\\sum_{j=0}^m \\binom{m=1}{j-1}p^{j-1}q^{m-1-(j-1}$$\n",
    "$$= mnp^2 + np \\quad \\because \\text{Binomial Theorem}$$\n",
    "$$= np(n-1)p + np$$\n",
    "$$= n^2p^2 + npq$$\n",
    "$$\\text{ }$$\n",
    "$$\\therefore \\sigma^2(binom[n,](x)) = n^2 p^2 - E[X]^2$$\n",
    "$$= n^2 p^2 + npq - (np)^2$$\n",
    "$$= np(np+q-np)$$\n",
    "$$= npq$$\n",
    "$$\\text{QED.}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that the binomial distribution considers sampling with replacement. It can be used to approximate sampling without replacement, if the number of items is high enough and $x$ small enough. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The **hypergeometric distribution** is the without-replacement equivalent to the binomial trial. It covers the more complex case when you have to account for the changes previous choices have on the probabilities of drawing from the remaining pot.\n",
    "* The binomial PDF is $P[X \\sim hypergeo[n, M, N](\\cdot) = x] = \\dfrac{\\binom{M}{x}\\binom{N-M}{n-x}}{\\binom{N}{n}}$; $M$ is the number of items in the set of the type desired. $n$ is the number of desired items that are desired (as $x$), and $N$ is the total number of items in the set.\n",
    "* $E[hypergeo[n, M, N](\\cdot)] = \\frac{nK}{M}$. Proof:\n",
    "\n",
    "$$E[hypergeo[n, M, N](\\cdot)] = \\sum_{i=0}^n x \\frac{\\binom{k}{x}\\binom{M-k}{n-x}}{\\binom{M}{n}}$$\n",
    "$$= \\sum_{i=1}^n x \\frac{\\binom{k}{x}\\binom{M-k}{n-x}}{\\binom{M}{n}}\\quad\\because\\text{term is 0 at $x$}$$\n",
    "$$= \\sum_{i=1}^nx\\frac{\\frac{k}{x}\\binom{k-1}{x-1}\\binom{M-k}{n-x}}{\\frac{M}{n}\\binom{M-1}{n-1}}\\quad\\because \\binom{n}{k} = \\frac{n}{k}\\binom{n-1}{k-1}\\text{ (twice)}$$\n",
    "$$= \\frac{nK}{M}\\sum_{i=1}^nx\\frac{\\binom{k-1}{x-1}\\binom{M-k}{n-x}}{\\binom{M-1}{n-1}}$$\n",
    "$$\\text{Let $j=i-1$. Then:}$$\n",
    "$$= \\sum_{j=0}^n\\frac{\\binom{k-1}{j}\\binom{M-1-(k-1)}{n-1-(x-1)}}{\\binom{M-1}{n-1}}$$\n",
    "$$= \\frac{nk}{M}\\sum_{j=0}^n hypergeo[n, N-1, M-1](\\cdot)$$\n",
    "$$= \\frac{nK}{M}(1)\\quad\\because\\text{ right side is just a summation of the total hypergeometric}$$\n",
    "$$= \\frac{nK}{M}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
